{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.50062519e-01  2.81646514e+02  6.91231398e-01  3.66233766e+02\n",
      "  1.19164955e-03 -1.48756240e+00  3.41303629e-03] [3.22038270e-02 5.73513373e+04 2.10258006e-01 2.71715298e+04\n",
      " 2.82422283e-06 8.08435506e-01 1.62027682e-05]\n",
      "tensor([[ 0.2137, -0.9813,  0.3443, -1.3118],\n",
      "        [-1.3892,  2.1468, -1.5075, -0.4018],\n",
      "        [-0.1467,  1.2952, -0.1105, -1.3118],\n",
      "        ...,\n",
      "        [-0.5492, -1.0449, -0.4156, -1.3118],\n",
      "        [ 0.5318, -0.3362,  0.6189, -1.3118],\n",
      "        [-0.1480,  1.6069, -0.2192,  1.4182]], dtype=torch.float64)\n",
      "tensor([[-0.6638,  0.2154, -0.4595],\n",
      "        [ 0.2894,  1.3408,  0.3171],\n",
      "        [ 0.0759, -0.8830,  0.2525],\n",
      "        ...,\n",
      "        [-0.1063,  0.8372, -0.2908],\n",
      "        [-0.0581, -0.8154, -0.0148],\n",
      "        [ 1.5723,  1.8359,  1.7354]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "\n",
    "book = xlrd.open_workbook('kinetic data for standardisation.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet1')\n",
    "data_unreplicated = [[sheet.cell_value(r, c)\n",
    "         for c in range(0,7)] for r in range(0,385)]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_unreplicated)\n",
    "\n",
    "print(scaler.mean_, scaler.var_)\n",
    "\n",
    "book = xlrd.open_workbook('prepareddatakinetic.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet1')\n",
    "replicated_data = [[sheet.cell_value(r, c)\n",
    "         for c in range(0,7)] for r in range(0,19201)]\n",
    "\n",
    "standardised_data = scaler.transform(replicated_data)\n",
    "np.random.shuffle(standardised_data)\n",
    "array1 = standardised_data[:, 0:4]\n",
    "array2 = standardised_data[:, 4:7]\n",
    "x = torch.tensor(array1)\n",
    "y = torch.tensor(array2)\n",
    "\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    " \n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1) \n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "  \n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H1, H2, D_out = 50, 4, 12, 9, 3\n",
    "model = Net(D_in, H1, H2, D_out)\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "train = torch.utils.data.TensorDataset(x, y)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=N,\n",
    "                                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(3.9142, grad_fn=<AddBackward0>)\n",
      "1 tensor(3.1875, grad_fn=<AddBackward0>)\n",
      "2 tensor(2.1254, grad_fn=<AddBackward0>)\n",
      "3 tensor(1.7027, grad_fn=<AddBackward0>)\n",
      "4 tensor(1.4960, grad_fn=<AddBackward0>)\n",
      "5 tensor(1.3618, grad_fn=<AddBackward0>)\n",
      "6 tensor(1.2706, grad_fn=<AddBackward0>)\n",
      "7 tensor(1.2051, grad_fn=<AddBackward0>)\n",
      "8 tensor(1.1543, grad_fn=<AddBackward0>)\n",
      "9 tensor(1.1091, grad_fn=<AddBackward0>)\n",
      "10 tensor(1.0633, grad_fn=<AddBackward0>)\n",
      "11 tensor(1.0157, grad_fn=<AddBackward0>)\n",
      "12 tensor(0.9690, grad_fn=<AddBackward0>)\n",
      "13 tensor(0.9326, grad_fn=<AddBackward0>)\n",
      "14 tensor(0.9076, grad_fn=<AddBackward0>)\n",
      "15 tensor(0.8901, grad_fn=<AddBackward0>)\n",
      "16 tensor(0.8778, grad_fn=<AddBackward0>)\n",
      "17 tensor(0.8683, grad_fn=<AddBackward0>)\n",
      "18 tensor(0.8612, grad_fn=<AddBackward0>)\n",
      "19 tensor(0.8557, grad_fn=<AddBackward0>)\n",
      "20 tensor(0.8513, grad_fn=<AddBackward0>)\n",
      "21 tensor(0.8472, grad_fn=<AddBackward0>)\n",
      "22 tensor(0.8451, grad_fn=<AddBackward0>)\n",
      "23 tensor(0.8412, grad_fn=<AddBackward0>)\n",
      "24 tensor(0.8386, grad_fn=<AddBackward0>)\n",
      "25 tensor(0.8365, grad_fn=<AddBackward0>)\n",
      "26 tensor(0.8350, grad_fn=<AddBackward0>)\n",
      "27 tensor(0.8330, grad_fn=<AddBackward0>)\n",
      "28 tensor(0.8312, grad_fn=<AddBackward0>)\n",
      "29 tensor(0.8302, grad_fn=<AddBackward0>)\n",
      "30 tensor(0.8285, grad_fn=<AddBackward0>)\n",
      "31 tensor(0.8276, grad_fn=<AddBackward0>)\n",
      "32 tensor(0.8261, grad_fn=<AddBackward0>)\n",
      "33 tensor(0.8244, grad_fn=<AddBackward0>)\n",
      "34 tensor(0.8236, grad_fn=<AddBackward0>)\n",
      "35 tensor(0.8223, grad_fn=<AddBackward0>)\n",
      "36 tensor(0.8219, grad_fn=<AddBackward0>)\n",
      "37 tensor(0.8211, grad_fn=<AddBackward0>)\n",
      "38 tensor(0.8199, grad_fn=<AddBackward0>)\n",
      "39 tensor(0.8190, grad_fn=<AddBackward0>)\n",
      "40 tensor(0.8194, grad_fn=<AddBackward0>)\n",
      "41 tensor(0.8170, grad_fn=<AddBackward0>)\n",
      "42 tensor(0.8168, grad_fn=<AddBackward0>)\n",
      "43 tensor(0.8161, grad_fn=<AddBackward0>)\n",
      "44 tensor(0.8154, grad_fn=<AddBackward0>)\n",
      "45 tensor(0.8145, grad_fn=<AddBackward0>)\n",
      "46 tensor(0.8146, grad_fn=<AddBackward0>)\n",
      "47 tensor(0.8138, grad_fn=<AddBackward0>)\n",
      "48 tensor(0.8133, grad_fn=<AddBackward0>)\n",
      "49 tensor(0.8128, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_epochs=50\n",
    "learning_rate=1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    avg_loss=0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        y_pred = model(x_batch.float())\n",
    "        loss = loss_fn(y_pred, y_batch.float())\n",
    "        avg_loss += loss/ len(train_loader.dataset)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(epoch,avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), (\"C:/Users/Gabriel/Documents/Python/ANNkinetic.pt\"))                \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01783333333333333, 24.988333333333344, 0.050833333333333335], [0.023416666666666665, -32.44333333333335, 0.04166666666666668], [0.02313333333333334, -9.365833333333322, 0.041666666666666664], [0.020691666666666674, 32.817499999999995, 0.034999999999999976], [0.019733333333333325, -26.63583333333334, 0.03500000000000003], [0.015975, 132.69500000000005, 0.02749999999999997], [0.01776666666666667, 242.3891666666666, 0.027500000000000007], [0.012699999999999989, 146.2941666666667, 0.029166666666666674], [0.013891666666666672, 193.01666666666657, 0.01416666666666666], [0.01153333333333332, 129.1691666666667, 0.025000000000000022], [0.009850000000000025, 118.19666666666672, 0.01833333333333335], [0.010924999999999999, 140.48833333333323, 0.00916666666666662]]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
