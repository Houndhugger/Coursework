{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "# Define the model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, hn = self.rnn(x, h0.detach())\n",
    "        out = self.fc(out) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define architecture\n",
    "input_dim = 5\n",
    "hidden_dim = 15\n",
    "layer_dim = 1 \n",
    "output_dim = 3\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#load trained model \n",
    "model.load_state_dict(torch.load(\"C:/Users/Gabriel/Documents/Python/RNN1.pt\"))\n",
    "model.eval()\n",
    "\n",
    "#load dataset used for standardisation\n",
    "book = xlrd.open_workbook('dataset for standardisation.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet1')\n",
    "data4 = [[sheet.cell_value(r, c)\n",
    "         for c in range(1,6)] for r in range(2,74)]\n",
    "data5 = [[sheet.cell_value(r, c)\n",
    "         for c in range(6,9)] for r in range(2,74)]\n",
    "scaler = StandardScaler()\n",
    "scaler2 = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset 7\n",
    "book = xlrd.open_workbook('Experimental Data edited.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet2')\n",
    "\n",
    "data = [[sheet.cell_value(r, c)\n",
    "         for c in range(1,6)] for r in range(114,126)]\n",
    "data2 = [[sheet.cell_value(r, c)\n",
    "         for c in range(1,4)] for r in range(114,126)]\n",
    "data3 = [[sheet.cell_value(r, c)\n",
    "         for c in range(1,4)] for r in range(115,127)]\n",
    "actual_results = torch.tensor(data3)\n",
    "\n",
    "scaler.fit(data4)\n",
    "scaler2.fit(data5)\n",
    "n = np.array(data)\n",
    "q = torch.tensor(n[:,:])\n",
    "\n",
    "#standarise data\n",
    "standardised_data = scaler.transform(data)\n",
    "standardised_data2 = standardised_data[:, 0:3] \n",
    "x_raw = torch.tensor(standardised_data[:,:])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        #sequence the data\n",
    "        x = x_raw.view(1,12,5)\n",
    "        #predict the rates of change\n",
    "        dx_dt_pred = model(x.float())\n",
    "        predictions = np.array(dx_dt_pred)\n",
    "        #descale the predictions\n",
    "        descaled_predictions = scaler2.inverse_transform(predictions)\n",
    "        usable_predictions = torch.tensor(descaled_predictions)\n",
    "        #add rates of change to previous timestep for prediction of values at the next timestep\n",
    "        q[:, 0:3]  = (usable_predictions*12) + q[:, 0:3]\n",
    "        np_x = np.array(q)\n",
    "          \n",
    "predictions_final = torch.tensor(np_x)\n",
    "x_plot = predictions_final.view(12, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate MAPE and generate graphs\n",
    "def MAPE(y_true, y_pred):\n",
    "    MAPE_Total=0\n",
    "    for i in range(len(y_pred)):\n",
    "        MAPE = torch.abs((y_true[i:1+i,:]-y_pred[i:1+i,:])/y_true[i:1+i,:])\n",
    "        MAPE_Total += (MAPE/len(y_pred))*100\n",
    "    return MAPE_Total\n",
    "\n",
    "import numpy as np\n",
    "a = np.linspace(12,144,12)\n",
    "v = torch.tensor(data3)\n",
    "print(v)\n",
    "import matplotlib.pyplot as plt \n",
    "y1 = x_plot[:, 0:1] \n",
    "x1 = a\n",
    "plt.plot(x1, y1,'o' ,label = \"predicted\") \n",
    "\n",
    "y2 = v[:, 0:1] \n",
    "x2 = a\n",
    "plt.plot(x2, y2, 'o',label = \"experimental\") \n",
    "plt.xlabel('time (h)')\n",
    "plt.ylabel('Biomass Conc (g/L)')\n",
    "loss = MAPE(v[:, 0:1],x_plot[:, 0:1])\n",
    "plt.title(('MAPE = {:.2f}'.format(loss.item())))\n",
    "plt.grid(b=True,which='major', axis='both')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "\n",
    "y1 = x_plot[:, 1:2] \n",
    "x1 = a\n",
    "plt.plot(x1, y1,'o',label = \"predicted\") \n",
    "\n",
    "y2 = v[:, 1:2] \n",
    "x2 = a\n",
    "plt.plot(x2, y2,'o',label = \"experimental\") \n",
    "plt.xlabel('time (h)')\n",
    "plt.ylabel('Nitrate Conc (mg/L)')\n",
    "loss = MAPE(v[:, 1:2],x_plot[:, 1:2])\n",
    "plt.title(('MAPE = {:.2f}'.format(loss.item())))\n",
    "plt.grid(b=True,which='major', axis='both')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "y1 = x_plot[:, 2:3] \n",
    "x1 = a\n",
    "plt.plot(x1, y1,'o',label = \"predicted\") \n",
    "\n",
    "y2 = v[:, 2:3] \n",
    "x2 = a\n",
    "plt.plot(x2, y2,'o',label = \"experimental\") \n",
    "plt.xlabel('time (h)')\n",
    "plt.ylabel('Lutein Conc (mg/L)')\n",
    "loss = MAPE(v[:, 2:3],x_plot[:, 2:3])\n",
    "plt.title(('MAPE = {:.2f}'.format(loss.item())))\n",
    "plt.grid(b=True,which='major', axis='both')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export results to excel\n",
    "import pandas as pd\n",
    "b=np.array(v)\n",
    "c=np.array(x_plot)\n",
    "book = xlrd.open_workbook('tested data.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet1')\n",
    "writer = pd.ExcelWriter('tested data.xlsx', engine='xlsxwriter')\n",
    "df1 = pd.DataFrame(b)\n",
    "df1.to_excel(writer, header=True, index=True)\n",
    "df2 = pd.DataFrame(c)\n",
    "df2.to_excel(writer, startrow=13, header=True, index=True)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
