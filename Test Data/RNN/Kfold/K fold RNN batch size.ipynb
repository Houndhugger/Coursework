{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "import numpy as np\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building your RNN\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # One time step\n",
    "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
    "        # This is part of truncated backpropagation through time (BPTT)\n",
    "        out, hn = self.rnn(x, h0.detach())\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out) \n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "       113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "       126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
      "       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "       165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,\n",
      "       178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
      "       191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203,\n",
      "       204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
      "       217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
      "       230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "       243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
      "       256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268,\n",
      "       269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
      "       282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "       295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "       308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
      "       321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
      "       334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
      "       347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359,\n",
      "       360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n",
      "       373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n",
      "       386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "       399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "       412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424,\n",
      "       425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
      "       438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
      "       451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "       464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
      "       477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "       490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502,\n",
      "       503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
      "       516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528,\n",
      "       529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541,\n",
      "       542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554,\n",
      "       555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,\n",
      "       568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580,\n",
      "       581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593,\n",
      "       594, 595, 596, 597, 598, 599]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 200, 201, 202, 203,\n",
      "       204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
      "       217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
      "       230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "       243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
      "       256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268,\n",
      "       269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
      "       282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "       295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "       308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
      "       321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
      "       334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
      "       347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359,\n",
      "       360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n",
      "       373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n",
      "       386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "       399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "       412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424,\n",
      "       425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
      "       438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
      "       451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "       464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
      "       477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "       490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502,\n",
      "       503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
      "       516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528,\n",
      "       529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541,\n",
      "       542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554,\n",
      "       555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,\n",
      "       568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580,\n",
      "       581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593,\n",
      "       594, 595, 596, 597, 598, 599]), array([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "       113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "       126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
      "       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "       165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,\n",
      "       178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
      "       191, 192, 193, 194, 195, 196, 197, 198, 199])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "       308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
      "       321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
      "       334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
      "       347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359,\n",
      "       360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n",
      "       373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n",
      "       386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n",
      "       399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "       412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424,\n",
      "       425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
      "       438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
      "       451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "       464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
      "       477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "       490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502,\n",
      "       503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
      "       516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528,\n",
      "       529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541,\n",
      "       542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554,\n",
      "       555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,\n",
      "       568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580,\n",
      "       581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593,\n",
      "       594, 595, 596, 597, 598, 599]), array([200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
      "       213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
      "       226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
      "       239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "       252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
      "       265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
      "       278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
      "       291, 292, 293, 294, 295, 296, 297, 298, 299])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
      "       412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424,\n",
      "       425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
      "       438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
      "       451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "       464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
      "       477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "       490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502,\n",
      "       503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
      "       516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528,\n",
      "       529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541,\n",
      "       542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554,\n",
      "       555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,\n",
      "       568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580,\n",
      "       581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593,\n",
      "       594, 595, 596, 597, 598, 599]), array([300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
      "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
      "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
      "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
      "       391, 392, 393, 394, 395, 396, 397, 398, 399])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 500, 501, 502,\n",
      "       503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
      "       516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528,\n",
      "       529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541,\n",
      "       542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554,\n",
      "       555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,\n",
      "       568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580,\n",
      "       581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593,\n",
      "       594, 595, 596, 597, 598, 599]), array([400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412,\n",
      "       413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425,\n",
      "       426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438,\n",
      "       439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451,\n",
      "       452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464,\n",
      "       465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
      "       478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
      "       491, 492, 493, 494, 495, 496, 497, 498, 499])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499]), array([500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512,\n",
      "       513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525,\n",
      "       526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538,\n",
      "       539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551,\n",
      "       552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564,\n",
      "       565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577,\n",
      "       578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       591, 592, 593, 594, 595, 596, 597, 598, 599]))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "\n",
    "book = xlrd.open_workbook('dataset for standardisation.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet1')\n",
    "data_unreplicated = [[sheet.cell_value(r, c)\n",
    "         for c in range(1,6)] for r in range(2,74)]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_unreplicated)\n",
    "\n",
    "\n",
    "book = xlrd.open_workbook('generateddatakfold.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet1')\n",
    "replicated_data = [[sheet.cell_value(r, c)\n",
    "         for c in range(0,5)] for r in range(0,7800)]\n",
    "\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    training_seq = []\n",
    "    label_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(0,L,13):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+1:i+tw+1,0:3]\n",
    "        training_seq.append(train_seq)\n",
    "        label_seq.append(train_label)\n",
    "    return training_seq,label_seq\n",
    "\n",
    "standardised_data = scaler.transform(replicated_data)\n",
    "array1 = standardised_data[:, 0:5]\n",
    "array2 = standardised_data[:, 5:8]\n",
    "x = torch.tensor(array1)\n",
    "\n",
    "z, t = create_inout_sequences(x, 12)\n",
    "x_train = torch.stack(z)\n",
    "y_train = torch.stack(t)\n",
    "\n",
    "n_splits = 6\n",
    "splits = list(KFold(n_splits=n_splits, shuffle=False, random_state=seed)\n",
    "              .split(x_train, y_train))\n",
    "print(splits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Gabriel\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Gabriel\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Gabriel\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "total loss=1.3344\n",
      "2\n",
      "total loss=1.2722\n",
      "3\n",
      "total loss=1.2422\n",
      "4\n",
      "total loss=1.3043\n",
      "5\n",
      "total loss=1.0943\n",
      "6\n",
      "total loss=1.3186\n",
      "7\n",
      "total loss=1.0703\n",
      "8\n",
      "total loss=0.9904\n",
      "9\n",
      "total loss=1.1714\n",
      "10\n",
      "total loss=1.2046\n",
      "20\n",
      "total loss=1.1994\n",
      "40\n",
      "total loss=1.3795\n",
      "60\n",
      "total loss=1.3849\n",
      "100\n",
      "total loss=1.0398\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "i = 5\n",
    "test_batchsizes = [1,2,3,4,5,6,7,8,9,10,20,40,60,100]\n",
    "train_epochs = 20\n",
    "learning_rate = 0.001\n",
    "input_dim = 5\n",
    "hidden_dim = 20\n",
    "layer_dim = 2  \n",
    "output_dim = 3\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "init_state_opt = copy.deepcopy(optimizer.state_dict())\n",
    "for batchsize in test_batchsizes:\n",
    "            input_dim = 5\n",
    "            hidden_dim = 20\n",
    "            layer_dim = 2  \n",
    "            output_dim = 3\n",
    "            model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "            total_loss = 0\n",
    "            init_state = copy.deepcopy(model.state_dict())\n",
    "            for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "                model.load_state_dict(init_state)\n",
    "                optimizer.load_state_dict(init_state_opt)\n",
    "                x_train_fold = torch.tensor(x_train[train_idx], dtype=torch.float32)\n",
    "                y_train_fold = torch.tensor(y_train[train_idx], dtype=torch.float32)\n",
    "                x_val_fold = torch.tensor(x_train[valid_idx], dtype=torch.float32)\n",
    "                y_val_fold = torch.tensor(y_train[valid_idx], dtype=torch.float32)\n",
    "                train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
    "                valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
    "                train_loader = torch.utils.data.DataLoader(train, batch_size=batchsize,\n",
    "                                                           shuffle=True)\n",
    "                valid_loader = torch.utils.data.DataLoader(valid, batch_size=batchsize,\n",
    "                                                           shuffle=False)\n",
    "                for epoch in range(train_epochs):\n",
    "                    model.train()\n",
    "                    avg_loss = 0.\n",
    "                    for x_batch, y_batch in train_loader:\n",
    "                        y_pred = model(x_batch)\n",
    "                        loss = loss_fn(y_pred, y_batch)\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                model.eval()\n",
    "                avg_val_loss = 0.\n",
    "                for x_batch, y_batch in valid_loader:\n",
    "                    y_pred = model(x_batch).detach()\n",
    "                    avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader.dataset)\n",
    "                    final_loss = avg_val_loss\n",
    "                total_loss += final_loss/(n_splits)\n",
    "            print(batchsize)\n",
    "            print('total loss={:.4f}'.format(total_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), (\"C:/Users/Gabriel/Documents/Python/ANN3.pt\"))                \n",
    "                                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
