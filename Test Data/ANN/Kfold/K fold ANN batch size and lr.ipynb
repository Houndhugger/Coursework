{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "import numpy as np\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1,H2,H3, D_out):\n",
    " \n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1) \n",
    "        self.linear2 = nn.Linear(H1, H2) \n",
    "        self.linear3 = nn.Linear(H2, H3) \n",
    "        self.linear4 = nn.Linear(H3, D_out)\n",
    "  \n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "seed_torch(seed)\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H1, H2, H3, D_out = 50, 5, 20, 15, 9, 3\n",
    "model = Net(D_in, H1, H2, H3, D_out)\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "init_state = copy.deepcopy(model.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "book = xlrd.open_workbook('dataset for standardisation.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet1')\n",
    "data_unreplicated = [[sheet.cell_value(r, c)\n",
    "         for c in range(1,9)] for r in range(2,74)]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_unreplicated)\n",
    "book = xlrd.open_workbook('prepareddatakfold.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet1')\n",
    "data_replicated = [[sheet.cell_value(r, c)\n",
    "         for c in range(0,8)] for r in range(0,7200)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_unreplicated)\n",
    "standardised_data = scaler.transform(data_replicated)\n",
    "\n",
    "x_train = standardised_data[:, 0:5]\n",
    "y_train = standardised_data[:, 5:8]\n",
    "\n",
    "n_splits = 6\n",
    "splits = list(KFold(n_splits=n_splits, shuffle=False, random_state=seed)\n",
    "              .split(x_train, y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.0001 29.666666666666668 2.0719595183266537\n",
      "10 0.0002 14.166666666666668 2.0668419076336755\n",
      "10 0.0003 41.666666666666664 1.8872614420784843\n",
      "10 0.0004 31.5 1.7162609992424644\n",
      "10 0.0005 19.833333333333332 1.8844458142254084\n",
      "10 0.0006 51.5 2.0063736837440067\n",
      "10 0.0007 7.333333333333333 2.082014009555181\n",
      "10 0.0008 53.5 1.9047508890098996\n",
      "10 0.0009 40.333333333333336 1.8406389227840634\n",
      "10 0.001 6.333333333333334 2.010044865873125\n",
      "10 0.002 26.5 1.6908967851930197\n",
      "10 0.003 25.5 1.8991099261575277\n",
      "10 0.004 17.5 1.9619858923885558\n",
      "10 0.005 24.833333333333336 1.6501416342125999\n",
      "10 0.006 25.166666666666664 1.873534408873982\n",
      "10 0.007 18.666666666666664 2.184431071413888\n",
      "10 0.008 5.5 2.2518505492475303\n",
      "10 0.009 37.833333333333336 2.2807803796397312\n",
      "10 0.01 54.33333333333333 2.36116404387686\n",
      "20 0.0001 45.33333333333333 2.0794489932060243\n",
      "20 0.0002 21.999999999999996 2.073979287412431\n",
      "20 0.0003 49.00000000000001 1.7596579061614144\n",
      "20 0.0004 10.833333333333332 2.0672160175111554\n",
      "20 0.0005 42.0 1.7410797507233091\n",
      "20 0.0006 67.99999999999999 2.0130033583111233\n",
      "20 0.0007 14.499999999999998 2.0258612015512254\n",
      "20 0.0008 9.0 2.0066367387771606\n",
      "20 0.0009 47.16666666666667 1.7590377194351619\n",
      "20 0.001 27.499999999999996 1.744818315903346\n",
      "20 0.002 35.83333333333333 1.9864604046609666\n",
      "20 0.003 6.666666666666667 2.098414690494537\n",
      "20 0.004 6.666666666666665 2.1089264906777276\n",
      "20 0.005 20.166666666666668 2.0763210262192624\n",
      "20 0.006 10.333333333333334 2.1241588714387682\n",
      "20 0.007 8.333333333333334 2.089713553587596\n",
      "20 0.008 4.833333333333333 2.105500111050076\n",
      "20 0.009 12.5 2.1224484584066605\n",
      "20 0.01 50.49999999999999 2.102189465363821\n",
      "30 0.0001 60.166666666666664 2.091169087092082\n",
      "30 0.0002 27.999999999999996 2.0835230045848423\n",
      "30 0.0003 18.666666666666668 2.088961176077525\n",
      "30 0.0004 14.166666666666666 2.0990359057320487\n",
      "30 0.0005 37.833333333333336 1.9096940167744954\n",
      "30 0.0006 14.333333333333334 2.079038436147902\n",
      "30 0.0007 22.666666666666664 2.0935156763924496\n",
      "30 0.0008 30.666666666666668 1.7747127159436542\n",
      "30 0.0009 13.5 2.053342599338955\n",
      "30 0.001 9.833333333333334 2.090797805256314\n",
      "30 0.002 32.166666666666664 1.7176980492803786\n",
      "30 0.003 3.1666666666666665 2.050329913033379\n",
      "30 0.004 20.833333333333332 2.0619120989905464\n",
      "30 0.005 3.3333333333333335 2.153309549225701\n",
      "30 0.006 19.5 1.9679017718633018\n",
      "30 0.007 5.166666666666666 2.0932780504226685\n",
      "30 0.008 2.0 2.0298564455244277\n",
      "30 0.009 2.6666666666666665 1.984526780446371\n",
      "30 0.01 8.666666666666666 1.7508377602365282\n",
      "40 0.0001 72.0 2.1027265993754067\n",
      "40 0.0002 34.0 2.092951323721144\n",
      "40 0.0003 22.333333333333332 2.0913899824354383\n",
      "40 0.0004 16.333333333333332 2.0961430448955958\n",
      "40 0.0005 13.666666666666666 2.1281071302625865\n",
      "40 0.0006 11.5 2.124765237172445\n",
      "40 0.0007 45.49999999999999 1.754699181980557\n",
      "40 0.0008 29.666666666666668 1.7589955539173552\n",
      "40 0.0009 35.833333333333336 1.7475996189647252\n",
      "40 0.001 27.833333333333336 1.7535298074616328\n",
      "40 0.002 7.500000000000001 2.028678429391649\n",
      "40 0.003 6.333333333333333 2.101089431974623\n",
      "40 0.004 2.8333333333333335 2.0982827154795327\n",
      "40 0.005 14.0 1.8668528604507444\n",
      "40 0.006 29.5 2.1013329691357083\n",
      "40 0.007 14.666666666666666 2.1458396418889363\n",
      "40 0.008 2.833333333333333 2.060706851217482\n",
      "40 0.009 8.666666666666666 2.151310455534193\n",
      "40 0.01 4.833333333333333 1.9468118074205187\n",
      "50 0.0001 43.33333333333333 2.3969844261805218\n",
      "50 0.0002 38.49999999999999 2.1036542903052435\n",
      "50 0.0003 26.666666666666668 2.106167913013034\n",
      "50 0.0004 19.499999999999996 2.130741538471646\n",
      "50 0.0005 15.499999999999998 2.1038227409786647\n",
      "50 0.0006 62.0 1.7585744931962755\n",
      "50 0.0007 49.333333333333336 1.776858450571696\n",
      "50 0.0008 57.99999999999999 2.0254112164179485\n",
      "50 0.0009 27.833333333333332 1.813898303243849\n",
      "50 0.001 26.333333333333336 1.8028659894731311\n",
      "50 0.002 11.333333333333334 2.1516852479510837\n",
      "50 0.003 5.833333333333333 2.154657885233561\n",
      "50 0.004 6.333333333333334 2.109889013502333\n",
      "50 0.005 4.500000000000001 2.070879504945543\n",
      "50 0.006 15.0 1.989296865463257\n",
      "50 0.007 15.666666666666666 2.0229987753762138\n",
      "50 0.008 20.0 2.023189131948683\n",
      "50 0.009 8.166666666666666 2.0613828319973417\n",
      "50 0.01 12.166666666666668 2.0320522901746965\n",
      "60 0.0001 49.83333333333333 2.400393182966444\n",
      "60 0.0002 44.833333333333336 2.112772378921509\n",
      "60 0.0003 30.0 2.1180723476409913\n",
      "60 0.0004 22.500000000000004 2.1209757995605467\n",
      "60 0.0005 65.66666666666666 2.1233280362023246\n",
      "60 0.0006 62.83333333333333 2.11863371319241\n",
      "60 0.0007 12.666666666666666 2.132942454020182\n",
      "60 0.0008 11.5 2.139176111221313\n",
      "60 0.0009 31.833333333333332 1.8498113197750516\n",
      "60 0.001 29.333333333333332 1.9131199667188856\n",
      "60 0.002 17.333333333333332 1.7792769082387287\n",
      "60 0.003 7.499999999999999 2.0389621395534943\n",
      "60 0.004 10.5 2.099814453125\n",
      "60 0.005 12.166666666666666 2.1211127016279434\n",
      "60 0.006 2.8333333333333335 2.1053834448920354\n",
      "60 0.007 15.666666666666666 2.1347253375583226\n",
      "60 0.008 17.833333333333332 2.052904487186008\n",
      "60 0.009 16.0 1.933754391140408\n",
      "60 0.01 11.5 1.9214675045013425\n",
      "70 0.0001 55.666666666666664 2.3991141135162777\n",
      "70 0.0002 50.0 2.1231123173236846\n",
      "70 0.0003 32.666666666666664 2.1279374918672773\n",
      "70 0.0004 24.166666666666664 2.1312793049547407\n",
      "70 0.0005 19.666666666666668 2.1313650035858154\n",
      "70 0.0006 17.166666666666668 2.1475637818707365\n",
      "70 0.0007 14.0 2.1451661058266955\n",
      "70 0.0008 11.166666666666666 2.154305277797911\n",
      "70 0.0009 27.166666666666664 1.7898842701647015\n",
      "70 0.001 8.833333333333336 2.175180806054009\n",
      "70 0.002 17.999999999999996 1.8712385879622566\n",
      "70 0.003 19.999999999999996 2.01577633884218\n",
      "70 0.004 5.666666666666667 2.060411221053865\n",
      "70 0.005 9.666666666666666 2.080770492553711\n",
      "70 0.006 3.9999999999999996 1.9186673225296866\n",
      "70 0.007 13.666666666666666 2.0691776667700874\n",
      "70 0.008 3.333333333333333 1.9153622823291356\n",
      "70 0.009 2.8333333333333335 2.0584955939981677\n",
      "70 0.01 36.0 2.00428133699629\n",
      "80 0.0001 63.00000000000001 2.399887180328369\n",
      "80 0.0002 54.66666666666667 2.1325020440419515\n",
      "80 0.0003 36.5 2.1398104349772136\n",
      "80 0.0004 27.833333333333332 2.1406243398454454\n",
      "80 0.0005 22.833333333333336 2.1418389786614314\n",
      "80 0.0006 18.833333333333332 2.1468758847978378\n",
      "80 0.0007 15.833333333333334 2.1586322085062664\n",
      "80 0.0008 12.666666666666666 2.161101320054796\n",
      "80 0.0009 11.499999999999998 2.1837612607744004\n",
      "80 0.001 26.166666666666668 1.900737844043308\n",
      "80 0.002 13.0 1.8990253596835664\n",
      "80 0.003 6.333333333333333 2.023423092100355\n",
      "80 0.004 7.666666666666665 2.0652786159515384\n",
      "80 0.005 4.166666666666667 2.1074365997314453\n",
      "80 0.006 8.833333333333334 2.0801645861731632\n",
      "80 0.007 21.333333333333332 1.9439606920878092\n",
      "80 0.008 7.5 2.125020850499471\n",
      "80 0.009 29.666666666666664 1.9555488957299128\n",
      "80 0.01 13.666666666666666 1.936941089630127\n",
      "90 0.0001 68.0 2.401347986857096\n",
      "90 0.0002 58.833333333333336 2.1401623593436345\n",
      "90 0.0003 39.66666666666667 2.138485336303711\n",
      "90 0.0004 29.833333333333332 2.146954657236735\n",
      "90 0.0005 23.0 2.1512151850594416\n",
      "90 0.0006 65.66666666666666 2.152012806998359\n",
      "90 0.0007 16.166666666666668 2.1612831905153063\n",
      "90 0.0008 14.166666666666668 2.165976759592692\n",
      "90 0.0009 12.666666666666666 2.1739034859339395\n",
      "90 0.001 10.833333333333334 2.1588331323199803\n",
      "90 0.002 15.0 1.864843621783786\n",
      "90 0.003 8.833333333333334 1.877594000498454\n",
      "90 0.004 8.333333333333334 1.9897679238849217\n",
      "90 0.005 51.0 2.0295948161019215\n",
      "90 0.006 7.833333333333333 1.896808682547675\n",
      "90 0.007 40.333333333333336 1.9223452165391712\n",
      "90 0.008 6.0 2.0084423626793755\n",
      "90 0.009 11.833333333333334 2.1236359776390925\n",
      "90 0.01 7.333333333333334 1.8799489540523953\n",
      "100 0.0001 75.16666666666667 2.401520375145806\n",
      "100 0.0002 63.333333333333336 2.1444126129150396\n",
      "100 0.0003 41.666666666666664 2.1466296429104275\n",
      "100 0.0004 31.833333333333336 2.155233774185181\n",
      "100 0.0005 26.000000000000004 2.162285479439629\n",
      "100 0.0006 20.333333333333336 2.1675376722547743\n",
      "100 0.0007 19.333333333333332 2.167437513139513\n",
      "100 0.0008 16.333333333333332 2.169768118328518\n",
      "100 0.0009 13.333333333333332 2.1638197114732534\n",
      "100 0.001 11.833333333333332 2.1708390776316326\n",
      "100 0.002 15.0 1.8682158078087703\n",
      "100 0.003 13.166666666666666 1.8309808158874512\n",
      "100 0.004 6.5 2.0445365884568956\n",
      "100 0.005 10.166666666666666 2.038530918757121\n",
      "100 0.006 5.0 2.0941348775227864\n",
      "100 0.007 6.833333333333334 1.8799875068664549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.008 18.666666666666664 2.0400714047749835\n",
      "100 0.009 3.833333333333333 2.020091220008003\n",
      "100 0.01 4.5 1.9121673976050482\n",
      "200 0.0001 67.16666666666667 2.946653162638346\n",
      "200 0.0002 69.5 2.4220233472188313\n",
      "200 0.0003 47.166666666666664 2.4296746995713976\n",
      "200 0.0004 52.83333333333333 2.185837624867757\n",
      "200 0.0005 42.16666666666667 2.1896661949157714\n",
      "200 0.0006 35.666666666666664 2.191034785376655\n",
      "200 0.0007 31.666666666666664 2.197102703518338\n",
      "200 0.0008 27.0 2.1946488783094615\n",
      "200 0.0009 23.666666666666668 2.1962683868408197\n",
      "200 0.001 21.833333333333336 2.1987237612406414\n",
      "200 0.002 31.166666666666664 1.7970598623487686\n",
      "200 0.003 19.666666666666664 1.8105630175272625\n",
      "200 0.004 15.5 1.8036084005567763\n",
      "200 0.005 10.666666666666666 1.8636262554592558\n",
      "200 0.006 16.833333333333336 1.7964844502343074\n",
      "200 0.007 6.999999999999999 1.9673876423305936\n",
      "200 0.008 7.666666666666665 1.9647176170349123\n",
      "200 0.009 9.833333333333334 1.964499782986111\n",
      "200 0.01 8.333333333333334 1.7861092546251085\n",
      "300 0.0001 98.16666666666666 2.9489128155178492\n",
      "300 0.0002 67.66666666666666 2.748926446702745\n",
      "300 0.0003 67.66666666666667 2.433907576666938\n",
      "300 0.0004 51.333333333333336 2.4368984095255533\n",
      "300 0.0005 42.166666666666664 2.439392903645833\n",
      "300 0.0006 50.99999999999999 2.2062931611802843\n",
      "300 0.0007 43.666666666666664 2.2083108393351236\n",
      "300 0.0008 38.33333333333333 2.210254198710124\n",
      "300 0.0009 34.0 2.210448955959744\n",
      "300 0.001 30.666666666666664 2.2147869915432397\n",
      "300 0.002 27.0 2.1902043279012045\n",
      "300 0.003 11.5 2.193224313524034\n",
      "300 0.004 16.833333333333332 1.8136935530768503\n",
      "300 0.005 14.833333333333334 1.8102002143859863\n",
      "300 0.006 12.499999999999998 1.8921566518147785\n",
      "300 0.007 10.5 1.9780079396565757\n",
      "300 0.008 22.166666666666668 2.0576714664035376\n",
      "300 0.009 13.499999999999998 1.8889083862304688\n",
      "300 0.01 10.0 1.8275217225816514\n",
      "400 0.0001 128.0 2.95116707695855\n",
      "400 0.0002 65.66666666666667 2.9577527364095046\n",
      "400 0.0003 88.83333333333333 2.4365148417154945\n",
      "400 0.0004 66.83333333333333 2.4397095828586157\n",
      "400 0.0005 53.33333333333333 2.442480053371853\n",
      "400 0.0006 45.833333333333336 2.442799546983507\n",
      "400 0.0007 38.83333333333333 2.4430653042263453\n",
      "400 0.0008 50.166666666666664 2.2190355682373046\n",
      "400 0.0009 43.99999999999999 2.2216702779134114\n",
      "400 0.001 40.16666666666667 2.22111082288954\n",
      "400 0.002 36.833333333333336 2.1989011383056645\n",
      "400 0.003 17.833333333333332 2.200115339491102\n",
      "400 0.004 28.500000000000004 1.823791804843479\n",
      "400 0.005 17.5 1.8398005506727428\n",
      "400 0.006 17.666666666666668 1.8108060455322266\n",
      "400 0.007 16.833333333333336 1.8163878928290473\n",
      "400 0.008 11.166666666666666 2.090917443169488\n",
      "400 0.009 10.666666666666666 1.940025634765625\n",
      "400 0.01 49.0 1.9396359422471787\n",
      "500 0.0001 146.0 3.0009488677978515\n",
      "500 0.0002 81.5 2.959418161180284\n",
      "500 0.0003 88.66666666666667 2.6432125261094837\n",
      "500 0.0004 81.83333333333333 2.4426543765597875\n",
      "500 0.0005 66.5 2.444790865580241\n",
      "500 0.0006 55.833333333333336 2.4444972780015735\n",
      "500 0.0007 47.833333333333336 2.44529173956977\n",
      "500 0.0008 42.333333333333336 2.444526850382487\n",
      "500 0.0009 38.0 2.4464968829684786\n",
      "500 0.001 48.333333333333336 2.227058465745714\n",
      "500 0.002 25.166666666666668 2.224945771959093\n",
      "500 0.003 17.666666666666668 2.206799831390381\n",
      "500 0.004 29.166666666666668 1.8138976754082574\n",
      "500 0.005 13.666666666666666 2.186989040374756\n",
      "500 0.006 17.333333333333332 1.8368010711669924\n",
      "500 0.007 23.166666666666668 1.7948556677500407\n",
      "500 0.008 22.833333333333332 1.8331764284769696\n",
      "500 0.009 13.499999999999998 1.925342752668593\n",
      "500 0.01 13.333333333333334 1.8012999598185222\n",
      "600 0.0001 161.83333333333331 3.0774749925401474\n",
      "600 0.0002 96.99999999999999 2.9607376692030165\n",
      "600 0.0003 64.5 2.9625170644124346\n",
      "600 0.0004 79.5 2.6466076660156252\n",
      "600 0.0005 79.00000000000001 2.4458993954128685\n",
      "600 0.0006 65.66666666666666 2.4470071834988065\n",
      "600 0.0007 56.833333333333336 2.447251273261176\n",
      "600 0.0008 50.5 2.4473506503634983\n",
      "600 0.0009 44.33333333333333 2.4475249057345922\n",
      "600 0.001 40.5 2.4454088253445097\n",
      "600 0.002 36.0 2.2256649017333983\n",
      "600 0.003 39.49999999999999 1.825326673719618\n",
      "600 0.004 16.666666666666668 2.201341620551215\n",
      "600 0.005 15.833333333333334 2.187710944281684\n",
      "600 0.006 32.333333333333336 1.8073721355862087\n",
      "600 0.007 18.0 1.8750083923339844\n",
      "600 0.008 18.0 1.8564769490559896\n",
      "600 0.009 33.16666666666667 1.7899489805433486\n",
      "600 0.01 14.000000000000002 1.91266603257921\n",
      "700 0.0001 170.33333333333331 3.1329002210829\n",
      "700 0.0002 108.0 2.961070268419054\n",
      "700 0.0003 72.16666666666667 2.9632068464491104\n",
      "700 0.0004 89.16666666666666 2.647781829833985\n",
      "700 0.0005 72.16666666666667 2.6493010372585726\n",
      "700 0.0006 74.16666666666666 2.447853512234158\n",
      "700 0.0007 62.83333333333334 2.4485345543755423\n",
      "700 0.0008 54.83333333333333 2.4489093356662326\n",
      "700 0.0009 50.16666666666666 2.448632431030273\n",
      "700 0.001 45.5 2.4471622890896265\n",
      "700 0.002 32.5 2.2275965711805554\n",
      "700 0.003 23.5 2.218328416612413\n",
      "700 0.004 17.666666666666664 2.2016181352403428\n",
      "700 0.005 17.666666666666664 2.190272488064236\n",
      "700 0.006 36.0 1.8002619213528102\n",
      "700 0.007 22.666666666666668 1.8454788080851239\n",
      "700 0.008 26.33333333333334 1.763094868130154\n",
      "700 0.009 25.333333333333336 1.821124988132053\n",
      "700 0.01 17.166666666666664 1.806065305074056\n",
      "800 0.0001 178.5 3.184851998223199\n",
      "800 0.0002 121.83333333333331 2.961263088650174\n",
      "800 0.0003 82.0 2.9641496192084418\n",
      "800 0.0004 61.33333333333334 2.9646774037679036\n",
      "800 0.0005 98.66666666666666 2.4478829362657333\n",
      "800 0.0006 83.00000000000001 2.4491787211100258\n",
      "800 0.0007 71.33333333333333 2.4510931142171226\n",
      "800 0.0008 62.50000000000001 2.4491605038113065\n",
      "800 0.0009 56.0 2.449177008734809\n",
      "800 0.001 51.0 2.448917956882053\n",
      "800 0.002 36.833333333333336 2.2310611131456164\n",
      "800 0.003 25.333333333333332 2.213639373779297\n",
      "800 0.004 42.666666666666664 1.8085785081651475\n",
      "800 0.005 19.666666666666668 2.2048585595024957\n",
      "800 0.006 17.0 2.192885954115126\n",
      "800 0.007 24.833333333333332 1.8220285246107315\n",
      "800 0.008 30.0 1.8022092734442818\n",
      "800 0.009 26.000000000000004 1.8355657450358074\n",
      "800 0.01 18.166666666666668 1.8244735505845813\n",
      "900 0.0001 190.5 3.2243213823106553\n",
      "900 0.0002 134.0 2.970136299133301\n",
      "900 0.0003 92.66666666666666 2.9650175052218968\n",
      "900 0.0004 69.66666666666666 2.9649633661905925\n",
      "900 0.0005 90.49999999999999 2.650988960266113\n",
      "900 0.0006 76.16666666666667 2.6519155205620657\n",
      "900 0.0007 80.5 2.4510285101996523\n",
      "900 0.0008 70.33333333333333 2.4504339684380425\n",
      "900 0.0009 63.166666666666664 2.449432258605957\n",
      "900 0.001 56.666666666666664 2.450815650092231\n",
      "900 0.002 41.333333333333336 2.2314383782280816\n",
      "900 0.003 28.333333333333336 2.216764645046658\n",
      "900 0.004 27.499999999999996 2.2008536105685765\n",
      "900 0.005 38.666666666666664 1.8196705669826934\n",
      "900 0.006 19.333333333333336 2.1828074603610568\n",
      "900 0.007 31.166666666666668 1.7926501634385852\n",
      "900 0.008 24.5 1.8293627527025007\n",
      "900 0.009 23.999999999999996 1.8342417060004341\n",
      "900 0.01 20.333333333333332 1.8872893820868597\n",
      "1000 0.0001 201.0 3.2528825039333764\n",
      "1000 0.0002 146.0 3.009409891764323\n",
      "1000 0.0003 107.83333333333334 2.96498104095459\n",
      "1000 0.0004 80.33333333333333 2.966004816691081\n",
      "1000 0.0005 104.0 2.651396747165256\n",
      "1000 0.0006 87.16666666666667 2.6519102096557616\n",
      "1000 0.0007 75.16666666666666 2.6525958167182075\n",
      "1000 0.0008 81.16666666666666 2.451534135606554\n",
      "1000 0.0009 72.33333333333333 2.451455709669325\n",
      "1000 0.001 65.33333333333333 2.4504482947455513\n",
      "1000 0.002 47.666666666666664 2.23453976949056\n",
      "1000 0.003 33.5 2.215990058051215\n",
      "1000 0.004 31.166666666666668 2.2028324932522243\n",
      "1000 0.005 22.33333333333333 2.1999156104193793\n",
      "1000 0.006 50.83333333333333 1.8302986250983344\n",
      "1000 0.007 19.833333333333336 2.1623121303982207\n",
      "1000 0.008 18.66666666666667 2.1605188496907552\n",
      "1000 0.009 29.833333333333336 1.7907964505089653\n",
      "1000 0.01 22.5 1.869534189436171\n"
     ]
    }
   ],
   "source": [
    "i = n_splits-1\n",
    "test_batchsizes = [10,20,30,40,50,60,70,80,90,100,200,300,400,500,600,700,800,900,1000]\n",
    "test_lrs = [0.0001,0.0002,0.0003,0.0004,0.0005,0.0006,0.0007,0.0008,0.0009,0.001,0.002,0.003,0.004,0.005,0.006,0.007,0.008,0.009,0.01]\n",
    "model = Net(D_in, H1, H2, H3, D_out)\n",
    "init_state = copy.deepcopy(model.state_dict())\n",
    "for batchsize in test_batchsizes:\n",
    "    for test_lr in test_lrs:\n",
    "            N, D_in, H1, H2,H3, D_out = batchsize, 5, 20 ,15 ,9 , 3\n",
    "            learning_rate=test_lr\n",
    "            av_opt_epoch=0\n",
    "            av_opt_loss=0\n",
    "            for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                model.load_state_dict(init_state)\n",
    "                x_train_fold = torch.tensor(x_train[train_idx], dtype=torch.float32)\n",
    "                y_train_fold = torch.tensor(y_train[train_idx], dtype=torch.float32)\n",
    "                x_val_fold = torch.tensor(x_train[valid_idx], dtype=torch.float32)\n",
    "                y_val_fold = torch.tensor(y_train[valid_idx], dtype=torch.float32)\n",
    "                train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
    "                valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
    "                train_loader = torch.utils.data.DataLoader(train, batch_size=batchsize,\n",
    "                                                           shuffle=True)\n",
    "                valid_loader = torch.utils.data.DataLoader(valid, batch_size=batchsize,\n",
    "                                                           shuffle=False)\n",
    "                UP=0\n",
    "                epoch=0\n",
    "                k=0\n",
    "                opt_loss=1000\n",
    "                old_avg_val_loss=0\n",
    "                while UP<4 and epoch<300:\n",
    "                    epoch+=1\n",
    "                    k+=1\n",
    "                    model.train()\n",
    "                    for x_batch, y_batch in train_loader:\n",
    "                        y_pred = model(x_batch)\n",
    "                        loss = loss_fn(y_pred, y_batch)\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    model.eval()\n",
    "                    avg_val_loss = 0.\n",
    "                    for x_batch, y_batch in valid_loader:\n",
    "                        y_pred = model(x_batch).detach()\n",
    "                        avg_val_loss += (loss_fn(y_pred, y_batch).item() / \n",
    "                        (len(valid_loader.dataset)))\n",
    "                    if k > 4:\n",
    "                        if avg_val_loss> old_avg_val_loss:\n",
    "                            UP+=1\n",
    "                        if avg_val_loss<old_avg_val_loss:\n",
    "                            UP=0\n",
    "                        old_avg_val_loss=avg_val_loss\n",
    "                        k=0\n",
    "                    if avg_val_loss<opt_loss:\n",
    "                        opt_loss = avg_val_loss\n",
    "                        opt_epoch = epoch\n",
    "                \n",
    "                av_opt_epoch+=opt_epoch/n_splits\n",
    "                av_opt_loss+=opt_loss/n_splits\n",
    "            print(batchsize,test_lr,av_opt_epoch,av_opt_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), (\"C:/Users/Gabriel/Documents/Python/ANN3.pt\"))                \n",
    "                                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
