{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# Define the model\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    " \n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1) \n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "  \n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import xlrd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "#define hyperparameters\n",
    "N, D_in, H1, H2, D_out = 100, 5, 15, 9, 3\n",
    "model = Net(D_in, H1, H2, D_out)\n",
    "\n",
    "#load trained parameters\n",
    "model.load_state_dict(torch.load(\"C:/Users/Gabriel/Documents/Python/ANN2.pt\"))\n",
    "model.eval()\n",
    "\n",
    "#load dataset used for standardisation\n",
    "book = xlrd.open_workbook('dataset for standardisation.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet1')\n",
    "data4 = [[sheet.cell_value(r, c)\n",
    "         for c in range(1,6)] for r in range(2,74)]\n",
    "data5 = [[sheet.cell_value(r, c)\n",
    "         for c in range(6,9)] for r in range(2,74)]\n",
    "scaler = StandardScaler()\n",
    "scaler2 = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset 4\n",
    "book = xlrd.open_workbook('Experimental Data edited.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet2')\n",
    "data = [[sheet.cell_value(r, c)\n",
    "         for c in range(1,6)] for r in range(98,110)]\n",
    "data2 = [[sheet.cell_value(r, c)\n",
    "         for c in range(1,4)] for r in range(98,110)]\n",
    "data3 = [[sheet.cell_value(r, c)\n",
    "         for c in range(1,4)] for r in range(99,111)]\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "v = torch.tensor(data3)\n",
    "scaler.fit(data4)\n",
    "scaler2.fit(data5)\n",
    "n = np.array(data)\n",
    "\n",
    "#unstandardised data used for the addition of unstandardised rate of change \n",
    "q = torch.tensor(n[:,:])\n",
    "\n",
    "#standardise data\n",
    "standardised_data = scaler.transform(data)\n",
    "standardised_data2 = standardised_data[:, 0:3] \n",
    "\n",
    "x = torch.tensor(standardised_data)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        #predict rate of change for every timestep\n",
    "        dx_dt_pred = model(x.float())\n",
    "        predictions = np.array(dx_dt_pred)\n",
    "        #descale predictions\n",
    "        descaled_predictions = scaler2.inverse_transform(predictions)\n",
    "        usable_predictions = torch.tensor(descaled_predictions)\n",
    "        #add the rate of change to previous timestep value\n",
    "        q[:, 0:3]  = (usable_predictions*12) + q[:, 0:3]\n",
    "        np_x = np.array(q[:, 0:3])\n",
    "        results = torch.tensor(np_x)\n",
    "        \n",
    "predictions_final = torch.tensor(results)  \n",
    "\n",
    "#compare results to true values\n",
    "x_plot = predictions_final.view(12, 3)\n",
    "print(x_plot) \n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate MAPE and generate graphs\n",
    "def MAPE(y_true, y_pred):\n",
    "    MAPE_Total=0\n",
    "    for i in range(len(y_pred)):\n",
    "        MAPE = torch.abs((y_true[i:1+i,:]-y_pred[i:1+i,:])/y_true[i:1+i,:])\n",
    "        MAPE_Total += (MAPE/len(y_pred))*100\n",
    "    return MAPE_Total\n",
    "\n",
    "import numpy as np\n",
    "a = np.linspace(12,144,12)\n",
    "v = torch.tensor(data3)\n",
    "import matplotlib.pyplot as plt \n",
    "y1 = x_plot[:, 0:1] \n",
    "x1 = a\n",
    "plt.plot(x1, y1,'o' ,label = \"predicted\") \n",
    "\n",
    "y2 = v[:, 0:1] \n",
    "x2 = a\n",
    "plt.plot(x2, y2, 'o',label = \"experimental\") \n",
    "plt.xlabel('time (h)')\n",
    "plt.ylabel('Biomass Conc (g/L)')\n",
    "loss = MAPE(v[:, 0:1],x_plot[:, 0:1])\n",
    "plt.title(('MAPE = {:.2f}'.format(loss.item())))\n",
    "plt.grid(b=True,which='major', axis='both')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "\n",
    "y1 = x_plot[:, 1:2] \n",
    "x1 = a\n",
    "plt.plot(x1, y1,'o',label = \"predicted\") \n",
    "\n",
    "y2 = v[:, 1:2] \n",
    "x2 = a\n",
    "plt.plot(x2, y2,'o',label = \"experimental\") \n",
    "plt.xlabel('time (h)')\n",
    "plt.ylabel('Nitrate Conc (mg/L)')\n",
    "loss = MAPE(v[:, 1:2],x_plot[:, 1:2])\n",
    "plt.title(('MAPE = {:.2f}'.format(loss.item())))\n",
    "plt.grid(b=True,which='major', axis='both')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "y1 = x_plot[:, 2:3] \n",
    "x1 = a\n",
    "plt.plot(x1, y1,'o',label = \"predicted\") \n",
    "\n",
    "y2 = v[:, 2:3] \n",
    "x2 = a\n",
    "plt.plot(x2, y2,'o',label = \"experimental\") \n",
    "plt.xlabel('time (h)')\n",
    "plt.ylabel('Nitrate Conc (mg/L)')\n",
    "loss = MAPE(v[:, 2:3],x_plot[:, 2:3])\n",
    "plt.title(('MAPE = {:.2f}'.format(loss.item())))\n",
    "plt.grid(b=True,which='major', axis='both')\n",
    "plt.legend()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export results to excel\n",
    "import pandas as pd\n",
    "b=np.array(v)\n",
    "c=np.array(x_plot)\n",
    "book = xlrd.open_workbook('tested data.xlsx')\n",
    "sheet = book.sheet_by_name('Sheet1')\n",
    "writer = pd.ExcelWriter('tested data.xlsx', engine='xlsxwriter')\n",
    "df1 = pd.DataFrame(b)\n",
    "df1.to_excel(writer, header=True, index=True)\n",
    "df2 = pd.DataFrame(c)\n",
    "df2.to_excel(writer, startrow=13, header=True, index=True)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
